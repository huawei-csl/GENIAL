# cocotb related imports
import cocotb
from cocotb.clock import Clock
from cocotb.triggers import RisingEdge, Timer
from cocotb.binary import BinaryRepresentation, BinaryValue

# from cocotb.regression import TestFactory
import logging

# import random

# imports needed for our functions
import numpy as np
import math


from pathlib import Path
import pandas as pd
from typing import Any
import random

import struct

def binary(num):
    # From https://stackoverflow.com/questions/16444726/binary-representation-of-float-in-python-bits-not-hex
    # Struct can provide us with the float packed into bytes. The '!' ensures that
    # it's in network byte order (big-endian) and the 'f' says that it should be
    # packed as a float. Alternatively, for double-precision, you could use 'd'.
    packed = struct.pack('!f', num)
    print('Packed: %s' % repr(packed))

    # For each character in the returned string, we'll turn it into its corresponding
    # integer code point
    # 
    # [62, 163, 215, 10] = [ord(c) for c in '>\xa3\xd7\n']
    # TODO: ord suold be mitted for python 3?
    integers = [ord(c) for c in packed]
    print('Integers: %s' % integers)

    # For each integer, we'll convert it to its binary representation.
    binaries = [bin(i) for i in integers]
    print('Binaries: %s' % binaries)

    # Now strip off the '0b' from each of these
    stripped_binaries = [s.replace('0b', '') for s in binaries]
    print('Stripped: %s' % stripped_binaries)

    # Pad each byte's binary representation's with 0's to make sure it has all 8 bits:
    #
    # ['00111110', '10100011', '11010111', '00001010']
    padded = [s.rjust(8, '0') for s in stripped_binaries]
    print('Padded: %s' % padded)

    # At this point, we have each of the bytes for the network byte ordered float
    # in an array as binary strings. Now we just concatenate them to get the total
    # representation of the float:
    return ''.join(padded)

class TestDatabaseInterface:
    """
    This class is used to interface with the database that stores the test results.
    """

    def __init__(self, db_filepath: Path, columns: list[str]) -> None:
        self.columns = columns 
        self.db_filepath = db_filepath
        self._init_dataframe(self.db_filepath, self.columns)

    def _init_dataframe(self, db_filepath: Path, columns: list[str]) -> None:
        """Initializes an empty DataFrame and saves it to a CSV file. Should be called by __init__ function of the class."""

        # Setup variables so tat they are all seen as strings
        variables = {col: str() for col in columns}
        self.df = pd.DataFrame(variables, index=[])
        # df.to_csv(db_filepath, index=False)  # Save to CSV with no index column

    def _update_dataframe(self, filepath: Path, new_data: list[Any]) -> None:
        """Updates an existing DataFrame in a CSV file with new data."""

        # try:
        #     df = pd.read_csv(filepath)
        # except FileNotFoundError:
        #     # If the file doesn't exist, initialize it
        #     raise ValueError(
        #         "File not found. Please use the MACTestDatabaseInterface class to initialize the database."
        #     )

        # Build the dictionary that will server to build add a row
        new_df = {col: [val] for col, val in zip(self.df.columns, new_data)}
        new_df = pd.DataFrame(new_df, columns=self.df.columns)
        df = pd.concat([self.df, new_df], ignore_index=True)

        # Save the updated Dataframe
        self.df = df

    def update_dataframe(self, new_data: list[Any]) -> None:
        """Updates an existing DataFrame in a CSV file with new data."""
        self._update_dataframe(self.db_filepath, new_data)

    def save_db(self) -> Path:
        """Saves the DataFrame to a CSV file."""
        self.df.to_csv(self.db_filepath, index=False)
        return self.db_filepath


clock_frequency_Mhz = 100
clock_period_ns = 1 / clock_frequency_Mhz * 1e3


# We will instantiate this TB object in every test so that all the required functions can be accessed
# from within this class.
class TestBench(object):
    """
    This is the top level testbench class.
    Args:
        dut: The DUT object that is passed to the testbench.

    """

    # The init method of this class can be used to do some setup like logging etc, start the
    # toggling of the clock and also initialize the internal to their pre-reset value.
    def __init__(self, dut, db_filepath:str|Path="results_db.csv"):
        self.dut = dut

        # Measure enabled range
        self.in_bitwidth = int(dut.N_IN)
        self.min_in_value = -(2**(self.in_bitwidth-1)) # Using positive and negative values - so range is divided by two
        self.max_in_value = -self.min_in_value - 1
        
        self.out_bitwidth = int(dut.N_OUT)
        self.min_out_value = -(2**(self.out_bitwidth-1)) # Using positive and negative values - so range is divided by two
        self.max_out_value = -self.min_out_value - 1

        self.log = logging.getLogger("cocotb_tb")
        self.log.setLevel(logging.DEBUG)

        self.wire_list = $wire_list

        self._db_columns = [
            "input_a_val",
            "input_a_rep",
            "input_b_val",
            "input_b_rep",
            "output_val",
            "output_rep",
        ] + self.wire_list

        self.results_db_if = TestDatabaseInterface(db_filepath=Path(db_filepath), columns=self._db_columns)

        # start the clock as a parallel process.
        cocotb.start_soon(Clock(self.dut.clk_ci, clock_period_ns, units="ns").start())
        self.log.info(f"Clock started with clock period of {clock_period_ns}ns")
        self.log.info(f"bitwidth read is {self.in_bitwidth} which is of type {type(self.in_bitwidth)}")

    def save_and_renew_database(self, db_filepath:str|Path) -> None:
        """ Replace the current database with a new one after saving the currently existing on as csv. """
        self.save_database()
        self.results_db_if = TestDatabaseInterface(db_filepath=Path(db_filepath), columns=self._db_columns)

    def save_database(self) -> None:
        """ Save the currently existing database as a csv file. """
        db_path = self.results_db_if.save_db()
        self.log.info(f"Database saved in {db_path}")
        

    # Note the 'async def' keyword here. It means that this is a coroutine that needs to
    # be awaited.
    async def cycle_reset(self):
        """Reset the DUT by asserting the reset signal for a few clock cycles."""
        self.dut.rst_ni.setimmediatevalue(1)
        await RisingEdge(self.dut.clk_ci)
        await RisingEdge(self.dut.clk_ci)
        self.dut.rst_ni.value = 0  # This is how cocotb lets you control the value of any signal inside the design
        await RisingEdge(self.dut.clk_ci)
        await RisingEdge(self.dut.clk_ci)
        self.dut.rst_ni.value = 1
        await RisingEdge(self.dut.clk_ci)
        await RisingEdge(self.dut.clk_ci)

def get_internal_values(tb, wire_list:list[str]):

    val_dict = {}
    val_list = []
    for wire in wire_list:
        # Note, wire should look like this: "i_mydesign_synthesized._05_"
        # Syntax from https://stackoverflow.com/a/72749551/9289815

        wire_value = tb.dut.i_mydesign_synthesized._id(wire, extended=False).value
        val_dict.update({wire:wire_value})
        val_list.append(wire_value)
    return val_dict, val_list
        # tb.log.info(tb.dut.i_mydesign_synthesized._id(wire, extended=False).value)


async def apply_values(tb, operand_a, operand_b):
    """Simply applies the right values to the right dut inputs."""

    _operand_a = BinaryValue(n_bits=tb.in_bitwidth, bigEndian=False, binaryRepresentation=BinaryRepresentation.TWOS_COMPLEMENT)
    _operand_b = BinaryValue(n_bits=tb.in_bitwidth, bigEndian=False, binaryRepresentation=BinaryRepresentation.TWOS_COMPLEMENT)
    _operand_a.signed_integer = operand_a
    _operand_b.signed_integer = operand_b
    # tb.log.info(type(tb.dut.operand_a_i.value))
    # tb.log.info(type(tb.dut.operand_a_i))
    
    # This seems to be working
    tb.dut.operand_a_i.value = _operand_a.value
    tb.dut.operand_b_i.value = _operand_b.value
    
    # This does not work
    # tb.dut.operand_a_i.value = _operand_a.get_buff()
    # tb.dut.operand_b_i.value = _operand_b.get_buff()
    from copy import copy
    
    
    if cocotb.plusargs.get("comb_only") is not None:
        # Because the IHP130 PDK does not give correct models for regiters
        # We removed them for simulation purposes
        await RisingEdge(tb.dut.clk_ci)
        a_val = copy(tb.dut.operand_a_i.value)
        b_val = copy(tb.dut.operand_b_i.value)
    else:
        a_val = copy(tb.dut.operand_a_i.value)
        b_val = copy(tb.dut.operand_b_i.value)
        await RisingEdge(tb.dut.clk_ci)
    
    # Read all internal values
    val_dict, val_list = get_internal_values(tb=tb, wire_list=tb.wire_list)

    # Save values
    if ('z' in a_val.binstr)\
        or ('z' in a_val.binstr):
        return None
    
    a_res = a_val.get_value_signed()
    b_res = b_val.get_value_signed()
    c_res = tb.dut.result_o.value.get_value_signed()
    # assert int(a_res) + int(b_res) == int(c_res)

    tb.results_db_if.update_dataframe([
            a_res,
            a_val.binstr.zfill(tb.in_bitwidth),
            b_res,
            b_val.binstr.zfill(tb.in_bitwidth),
            c_res,
            tb.dut.result_o.value.binstr,
            ]+val_list)
    
async def sweep_test(tb):
    a:int
    b:int
    for a in range(tb.min_in_value, tb.max_in_value+1):
        tb.log.info(f"Testing values: a={a}")
        for b in range(tb.min_in_value, tb.max_in_value+1):
            if (a+b) < tb.min_in_value or (a+b) > tb.max_in_value:
                pass
            else:
                try:
                    await apply_values(tb, a, a)
                except Exception as e:
                    tb.log.error(f"Error on values: a={a}, b={b}")
                    a_bin = BinaryValue(a, n_bits=0, binaryRepresentation=BinaryRepresentation.SIGNED_MAGNITUDE)
                    b_bin = BinaryValue(b, n_bits=0, binaryRepresentation=BinaryRepresentation.SIGNED_MAGNITUDE)
                    tb.log.error(f"a = {a_bin.binstr}, b = {b_bin.binstr}")
                    tb.log.error(f"Received exception {e}")
                    tb.results_db_if.update_dataframe([
                        a,
                        "error",
                        b,
                        "error",
                        a+b,
                        "error",
                        ""
                        ])
                
                # Read all values
                a_val = tb.dut.operand_a_i.value
                b_val = tb.dut.operand_b_i.value
                out_val = tb.dut.result_o.value
    await apply_values(tb, a, b)


async def full_sweep_test(tb):
    """ Test that applies all possible switching pairs """
    a:int
    b:int

    all_pairs = []
    for a in range(tb.min_in_value, tb.max_in_value+1):
        for b in range(tb.min_in_value, tb.max_in_value+1):
            all_pairs.append((a,b))
    
    for idx, curr_pair in enumerate(all_pairs):
        curr_a, curr_b = curr_pair 
        await apply_values(tb, curr_a, curr_b)
        for next_pair in all_pairs[idx+1:]:
            next_a, next_b = next_pair
            await apply_values(tb, next_a, next_b)
            await apply_values(tb, curr_a, curr_b)
    
    await apply_values(tb, a, b)


async def uniform_random_test(tb, nb_iter=1000000):

    count = 0
    while count != nb_iter:
        a = random.randint(tb.min_in_value,tb.max_in_value)
        b = random.randint(tb.min_in_value,tb.max_in_value)
        await apply_values(tb, a, b)
        count += 1


async def normal_random_test(tb, nb_iter=1000000):
    def sample():
        # Define the desired range and sample size
        lower_bound = tb.min_in_value
        upper_bound = tb.max_in_value

        # Sample from a standard normal distribution
        a_samples = np.random.normal(loc=0, scale=1, size=nb_iter)  #Mean = 0, Std Dev = 1
        b_samples = np.random.normal(loc=0, scale=1, size=nb_iter)  #Mean = 0, Std Dev = 1

        # Scale and shift to the desired range
        a_scaled_samples = a_samples * ((upper_bound - lower_bound) / 6) + ((upper_bound + lower_bound) / 2)  
        b_scaled_samples = b_samples * ((upper_bound - lower_bound) / 6) + ((upper_bound + lower_bound) / 2)  

        # Round to integers
        a_integers = np.round(a_scaled_samples).astype(int)
        b_integers = np.round(b_scaled_samples).astype(int)

        # Clip to the desired range
        a_clipped_integers = np.clip(a_integers, lower_bound, upper_bound)
        b_clipped_integers = np.clip(b_integers, lower_bound, upper_bound)
        return a_clipped_integers, b_clipped_integers

    a_vals, b_vals = sample()
    
    count = 0
    idx = 0
    while count != nb_iter:
        a = a_vals[idx]
        b = b_vals[idx]
        idx += 1

        if idx == nb_iter:
            a_vals, b_vals = sample()
            idx = 0

        await apply_values(tb, a, b)
        count += 1


@cocotb.test()  # decorator indicates that this is a test that needs to be run by cocotb.
async def test1(dut):  # dut is a pointer to the top module. This is built in
    tb = TestBench(dut, db_filepath="results_sweep_db")  # creating a testbench object for this dut. __init__ function is run automatically
    
    await Timer(1)  # pauses current function and lets the simulator run for 1 time step.
    # duration of each timestep is determined by the parameter #COCOTB_HDL_TIMEPRECISION in the makefile

    tb.dut._log.info("resetting the module") 

    tb.save_and_renew_database(db_filepath="results_fullsweep_db.csv")

    await tb.cycle_reset()  
    tb.dut._log.info("out of reset")

    ####################
    # SWEEP TEST
    ####################
    await full_sweep_test(tb) 

    await RisingEdge(tb.dut.clk_ci)
    await RisingEdge(tb.dut.clk_ci)

    tb.save_and_renew_database(db_filepath="results_uniform_rand_db.csv")

    ####################
    # RANDOM UNIFORM TEST
    ####################
    #await tb.cycle_reset()  
    #await uniform_random_test(tb, int(4096))

    #await RisingEdge(tb.dut.clk_ci)
    #await RisingEdge(tb.dut.clk_ci)

    tb.save_and_renew_database(db_filepath="results_normal_rand_db.csv")
    
    ####################
    # RANDOM NORMAL TEST
    ####################
    await tb.cycle_reset()  
    await normal_random_test(tb, int(4096))

    await RisingEdge(tb.dut.clk_ci)
    await RisingEdge(tb.dut.clk_ci)

    tb.save_database()
    
    assert True
